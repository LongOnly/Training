{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298294b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from selenium import webdriver\n",
    "from trafilatura import extract\n",
    "\n",
    "\n",
    "def query(string):\n",
    "    '''\n",
    "    This function checks all columns for a given string, starting on Article Text column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        contains the content of rows associated with the respective column where string matched\n",
    "    '''\n",
    "    for column in db.columns:\n",
    "        contents = [i for i in db[column].dropna()\n",
    "                    if str(string).lower() in i.lower()]\n",
    "        if contents:\n",
    "            return contents\n",
    "        else:\n",
    "            pass\n",
    "    print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ae0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the database already exists, read it\n",
    "if path.isfile('db.h5'):\n",
    "    db = pd.read_hdf('db.h5')\n",
    "\n",
    "# otherwise initialize it with all the columns\n",
    "else:\n",
    "    db = pd.DataFrame({},columns=['Article Text','Author','Headline','Article URL','Source Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch chromedriver and start reading the designated webpage\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.bloomberg.com/technology')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for all the links in the webpage\n",
    "elements = driver.find_elements_by_xpath('//a[contains(@href, \"%s\")]' % '/articles/')\n",
    "\n",
    "# on every link, identify headline, url and attribute them to the designated source\n",
    "for article in elements:\n",
    "    entry = len(db)\n",
    "    headline = article.text.split('\\n')[0]\n",
    "    if headline:\n",
    "        db.loc[entry, 'Headline'] = headline\n",
    "        db.loc[entry, 'Article URL'] = article.get_attribute('href').split('?')[0]\n",
    "        db.loc[entry, 'Source Name'] = 'Bloomberg Technology'\n",
    "\n",
    "# grab the index entries of this source links\n",
    "bloomberglinks = db[(db['Source Name'] == 'Bloomberg Technology')\n",
    "                    & pd.isna(db['Article Text'])].index\n",
    "\n",
    "# for each entry, visit the url and collect the contents\n",
    "for link in bloomberglinks:\n",
    "    try:\n",
    "        driver.get(db['Article URL'][link])\n",
    "        keys = driver.find_element_by_xpath('//*[address]')\n",
    "\n",
    "        for values in keys.text.split('\\n'):\n",
    "            if values[0:2] == 'By':\n",
    "                db.loc[link, 'Author'] = values[3:]\n",
    "\n",
    "        db.loc[link, 'Article Text'] = extract(driver.page_source)\n",
    "        sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# close chromedriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4042f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes there are duplicates articles in this webpage\n",
    "db = db.drop_duplicates().reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88df0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://elcomercio.pe/economia/?ref=ecr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for all the headlines, authors and links in the webpage\n",
    "elements = driver.find_elements_by_xpath('//h2[a]')\n",
    "authors = driver.find_elements_by_xpath('//a[contains(@href, \"%s\")]' % '/autor')\n",
    "links = driver.find_elements_by_xpath('//h2//*[@href]')\n",
    "\n",
    "# save each in the database and attribute them to the designated source\n",
    "for i, headline in enumerate(elements):\n",
    "    entry = len(db)\n",
    "    db.loc[entry, 'Headline'] = headline.text\n",
    "    db.loc[entry, 'Author'] = authors[i].text\n",
    "    db.loc[entry, 'Article URL'] = links[i].get_attribute('href')\n",
    "    db.loc[entry, 'Source Name'] = 'El Comercio'\n",
    "\n",
    "elcomerciolinks = db[(db['Source Name'] == 'El Comercio')\n",
    "                     & pd.isna(db['Article Text'])].index\n",
    "\n",
    "for link in elcomerciolinks:\n",
    "    try:\n",
    "        driver.get(db['Article URL'][link])\n",
    "        db.loc[link, 'Article Text'] = extract(driver.page_source)\n",
    "        sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(query('Alphabet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query('Alphabet')[0]#.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0be44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_hdf('db.h5', key='articles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
